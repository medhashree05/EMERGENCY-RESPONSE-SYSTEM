import React, { useRef, useState } from 'react'

export default function VoiceRecorder({ onSendAudio }) {
  const mediaRecorderRef = useRef(null)
  const audioChunksRef = useRef([]) 
  const [isRecording, setIsRecording] = useState(false)
  const streamRef = useRef(null) 

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000 
        }
      })
      
      streamRef.current = stream
      audioChunksRef.current = [] // ‚úÖ Clear previous chunks

      // Determine best MIME type
      const options = {
        mimeType: 'audio/webm;codecs=opus',
      }

      if (!MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        if (MediaRecorder.isTypeSupported('audio/webm')) {
          options.mimeType = 'audio/webm'
        } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
          options.mimeType = 'audio/mp4'
        } else if (MediaRecorder.isTypeSupported('audio/ogg')) {
          options.mimeType = 'audio/ogg'
        }
      }

      console.log('üé§ Using MIME type:', options.mimeType)

      mediaRecorderRef.current = new MediaRecorder(stream, options)

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          console.log(`üì¶ Chunk: ${(event.data.size / 1024).toFixed(2)} KB`)
          audioChunksRef.current.push(event.data) // ‚úÖ Push to ref, not state
        }
      }

      mediaRecorderRef.current.onstop = async () => {
        console.log(`‚èπÔ∏è Recording stopped. Chunks: ${audioChunksRef.current.length}`)
        
        // ‚úÖ Now audioChunksRef has the correct data
        if (audioChunksRef.current.length === 0) {
          onSendAudio('‚ö†Ô∏è No audio recorded. Please try again.')
          cleanup()
          return
        }

        const mimeType = mediaRecorderRef.current.mimeType
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType })
        
        console.log(`üéµ Blob created: ${(audioBlob.size / 1024).toFixed(2)} KB`)

        if (audioBlob.size < 1000) {
          onSendAudio('‚ö†Ô∏è Recording too short. Please speak for longer.')
          cleanup()
          return
        }

        // Determine file extension
        let fileName = 'voice.webm'
        if (mimeType.includes('mp4')) fileName = 'voice.mp4'
        else if (mimeType.includes('wav')) fileName = 'voice.wav'
        else if (mimeType.includes('ogg')) fileName = 'voice.ogg'

        const audioFile = new File([audioBlob], fileName, { type: mimeType })

        try {
          const formData = new FormData()
          formData.append('file', audioFile)

          console.log(`üì§ Sending: ${fileName}, ${(audioFile.size / 1024).toFixed(2)} KB`)

          const res = await fetch('http://localhost:8000/transcribe', {
            method: 'POST',
            body: formData,
          })

          if (!res.ok) {
            const errorData = await res.json().catch(() => ({ error: 'Unknown error' }))
            throw new Error(errorData.error || `HTTP ${res.status}`)
          }

          const data = await res.json()
          console.log('‚úÖ Response:', data)

          if (data.success && data.text && data.text.trim()) {
            onSendAudio(data.text.trim())
          } else if (data.success) {
            onSendAudio('‚ö†Ô∏è No speech detected in audio.')
          } else {
            throw new Error(data.error || 'Transcription failed')
          }
        } catch (err) {
          console.error('‚ùå Transcription error:', err)
          onSendAudio(`‚ö†Ô∏è Transcription failed: ${err.message}`)
        } finally {
          cleanup()
        }
      }

      mediaRecorderRef.current.onerror = (error) => {
        console.error('‚ùå MediaRecorder error:', error)
        onSendAudio('‚ö†Ô∏è Recording error occurred.')
        cleanup()
      }

      // ‚úÖ Start with timeslice to get chunks during recording
      mediaRecorderRef.current.start(1000) // Chunk every 1 second
      setIsRecording(true)
      console.log('üî¥ Recording started')

    } catch (err) {
      console.error('‚ùå Mic access error:', err)
      let message = '‚ö†Ô∏è Microphone access denied.'
      
      if (err.name === 'NotAllowedError') {
        message = '‚ö†Ô∏è Please allow microphone access in browser settings.'
      } else if (err.name === 'NotFoundError') {
        message = '‚ö†Ô∏è No microphone found. Please connect one.'
      }
      
      onSendAudio(message)
      cleanup()
    }
  }

  const stopRecording = () => {
    console.log('‚è∏Ô∏è Stopping recording...')
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
    }
  }

  const cleanup = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop())
      streamRef.current = null
    }
    audioChunksRef.current = []
  }

  return (
    <div className="voice-recorder">
      {!isRecording ? (
        <button
          className="voice-btn start-recording"
          onClick={startRecording}
          title="Start voice recording"
        >
          üé§ Start
        </button>
      ) : (
        <button
          className="voice-btn stop-recording"
          onClick={stopRecording}
          title="Stop recording and transcribe"
        >
          ‚èπ Stop
        </button>
      )}
    </div>
  )
}